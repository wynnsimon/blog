大模型和人类的思想并不相同，它的思考本质上是文字接龙是概率模型，通过推理当前文字后面大概率出现的文字来回答问题

大模型应用场景：
- 自然语言处理（NLP）
- 语音处理（SLP）
- 图像视频处理

# 提示词工程
ai回答的准确与否并不很大程度上取决于模型的能力，而是很大程度上取决于前面的信息准确与否

> [!NOTE]
> 提示工程（Prompt Engineering）是一项通过优化提示词（Prompt）和生成策略，从而获得更好的模型返回结果的工程技术。

好的提示词需要不断调优，其中要具体描述清楚自己想要什么，并告诉ai细节，不能让ai去猜测

**提示词通常包括以下内容：**
- 指示（lnstruction）：描述要让它做什么？
- 上下文（Context）：给出与任务相关的背景信息
- 例子（Examples）：给出一些例子，让模型知道怎么回复
- 输入（lnput）：任务的输入信息
- 输出（OutputFormat）：输出的格式，想要什么形式的输出？
示例：
```python
instruction = "根据下面的上下文回答问题。保持答案简短且准确"
context= "Teplizumab起源于一个位于新泽西的药品公司"
query="OKT3最初是从什么来源提取的？"

# 封装提示词
prompt = f"""{instruction} ### 上下文{context} ### 问题：{query}"""
```

# RAG
检索增强生成（Retrieval Augmented Generation）技术是一种结合信息检索与生成模型的新型架构，其核心思想是利用外部知识库或文档集合为大模型提供实时、准确的背景信息，从而弥补大模型的局限性。

**为什么需要RAG：**
大模型的知识完全来自训练数据，存在以下局限：
1. 知识过时：无法知道训练数据之后的事件
2. 幻觉问题：编造看似合理但错误的信息
3. 缺乏特定领域知识：如公司内部文档、专业数据库

普通的检索（关键字检索）如红线所示：用户的查询直接发送给大模型，大模型直接给出回答
rag（向量检索：方向一致）的回答：用户给出的查询先发送给检索者，检索者拿到问题后会在知识库检索与用户查询相关的文档，并将用户的查询和检索出的文档一并发送给大模型，大模型根据这些数据以及自己已有的信息给出回答
![](attachments/Pasted%20image%2020260124121353.png)

**RAG由两部分组成：**
1. 检索模块：在知识库中检索与当前输入问题相关的文档或片段。
2. 生成模块：基于检索结果和原始输入，通过大模型生成准确、丰富的回答。

### 检索方案
- 关键字检索：只能对特定的已经存在的问题进行检索，不存在的问题解答不了
- 生成模式：将已有的知识喂给ai，模型总结并微调，这种方法需要一定的成本（训练模型），并且准确性也无法保证，通常需要人工协作（将问题给到客服，客服去模型中查问题，拿到回答后再经过一定的修饰回答给客户）
- rag：知识库中的数据进行分词处理、向量化（将同一类型的问题归一到同一向量）、筛选、清洗等整理后进行rag检索
![](attachments/Pasted%20image%2020260124123229.png)

## 文档分割

文档分割是为了更好的构建知识库，一个文档中通常会只有很少一部分是与用户提出的问题相关的，而大部分可能涉及多种方向，对文档进行切割可以将知识进行分类，增加相关度

有多种方式：
1. 根据句子分割：句子段落，一个句子一个chunk
2. 按照字符数切分：设置固定的字符数，缺点不连贯
3. 按照固定字符：设置固定的字符，结合一定的重复字符
4. 递归方法：设置固定的字符，结合一定的重复字符，在加对应的语义
5. 根据语义进行分割：语义




